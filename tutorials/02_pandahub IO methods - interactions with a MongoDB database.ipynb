{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandahub IO methods\n",
    "\n",
    "This tutorial briefly demonstrates how to use the pandahub IO methods. This includes high level functions for commonly used database interactions like reading and writing grid data or timeseries data from/to a MongoDB database. pandahub IO methods do not need any additional configuration. Just call a pandahub API object (see the `01_pandahub API - interaction with a MongoDB database tutorial`) and directly use its IO interaction methods.\n",
    "\n",
    ">**Note**\n",
    ">\n",
    ">To run this tutorial you need a config file containing the database server URL and authentification information (For more information check out the tutorial `01_pandahub API - interaction with a MongoDB database tutorial`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Call pandahub api and activate project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At first we need to call a pandahub API object\n",
    "import pandahub as ph\n",
    "from config import MONGODB_URL\n",
    "\n",
    "ph_api = ph.PandaHub(connection_url=MONGODB_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a next step, check if your project, you want to interact with, exists. If so, we activate the particular project. \n",
    "\n",
    ">**Note**\n",
    ">\n",
    ">If not, you need to create the project first. If you don't know how to do that, please check out '01_pandahub API - call a MongoDB database'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_api.project_exists('MyAwesomeFirstProject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_api.set_active_project('MyAwesomeFirstProject')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, you finally are able to work with your database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Interaction with the MongoDB database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example how to write and read a pandapower/pandapipes net as well as timeseries data. If `return_id` is set to True, the method returns the unique identifier of the document that is written to the database. You can also add custom kwargs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write/Read a pandapower/pandapipes net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this subsection, we explain how to write and read pandapower and pandapipes networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pandapower**\n",
    "\n",
    "At first we need to load a pandapower net. In our example we load the `mv_oberrhein` network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandapower import networks as nws\n",
    "\n",
    "net_orig = nws.mv_oberrhein()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This net looks like follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandapower.plotting import simple_plot\n",
    "\n",
    "simple_plot(net_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As next step, we write the net to our database we just activated before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_api.write_network_to_db(net_orig, 'MyAwesomeNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrting a net to our database, each pandas DataFrame is written into a corresponding collection. General information of a net is saved under `_networks`.\n",
    "\n",
    "Besides the way described above, there is another alternative way to write a network to the database. \n",
    "Instead of activating your project like described in section 1, you are also able to directly pass the `project id` within the `write_network_to_db` function. Doing so, the project gets activated automatically. To show this, we again call the pandahub api first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_api = ph.PandaHub(connection_url=MONGODB_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you try to write the net to the database now, you get the error message, that the project is not activated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_api.write_network_to_db(net_orig, 'MyAwesomeNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as soon as you pass a `project id`, the project gets activated on the fly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_api.write_network_to_db(net_orig, 'MyAwesomeNet', project_id='Awesome')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The net is now saved in the database and can be called:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_db = ph_api.get_net_from_db('MyAwesomeNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the original net with the net retrieved from the database shows that both nets are equal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandapower as pp\n",
    "from pandapower.toolbox import nets_equal\n",
    "\n",
    "pp.runpp(net_db)\n",
    "pp.runpp(net_orig)\n",
    "\n",
    "nets_equal(net_orig, net_db, check_only_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of writing a net to or reading a net from a database, it is also possible to just call and modify single values. Reading a single value can be done by calling following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_api.get_net_value_from_db('MyAwesomeNet', 'load', 0, 'p_mw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To change this value, you need to call following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_api.set_net_value_in_db('MyAwesomeNet', 'load', 0, 'p_mw', 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the value again, shows that the value has been modified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_api.get_net_value_from_db('MyAwesomeNet', 'load', 0, 'p_mw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pandapipes**\n",
    "\n",
    "Likewise as in the pandapower example, we need to load a pandapipes networks first. We could have chosen a network with georeferenced data points, however, there is no network example given covering most of the pandapipes components. Therefore we chose a generic network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandapipes import networks as nws\n",
    "\n",
    "net_orig = nws.gas_versatility()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As next step we upload the net to our database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_api.write_network_to_db(net_orig, 'MyAwesomePandapipesNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving this net from the database again and comparing it to the original networks leads to same results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandapipes as pps\n",
    "from pandapipes.toolbox import nets_equal\n",
    "\n",
    "net_db = ph_api.get_net_from_db('MyAwesomePandapipesNet')\n",
    "\n",
    "pps.pipeflow(net_db)\n",
    "pps.pipeflow(net_orig)\n",
    "\n",
    "nets_equal(net_orig, net_db, check_only_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write/Read a time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedure to call a single or multiple time series diverge. The differences are hightlighted in the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Single time series**\n",
    "\n",
    "At first, we call the pandahub api again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_api = ph.PandaHub(connection_url=MONGODB_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to write a time series to the pandahub database, you need to ask yourself, if the time series shall be globally or project specific available. If you define it globally, you can access the time series without calling a specific project. \n",
    "\n",
    "In the following, we show how to upload a randomly created time series for global use. If you assign it project specific, you need to pass a `project_id` or activate a project beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "timeseries_data = pd.Series(np.random.random(35040))\n",
    "ph_api.write_timeseries_to_db(timeseries_data, \n",
    "                              data_type='p_mw', \n",
    "                              collection_name=\"timeseries\", \n",
    "                              global_database=True, \n",
    "                              compress_ts_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing the time series data you need to define a data type. The recommended format is `<type>_<unit>`. Moreover, you can also compress your time series data. The main advantages of compressing your data are, that you can read time series from and write time series to the data base much faster. Furthermore, the time series occupies much less space. However, you should also always keep the drawbacks in mind. To make use of the advantages, the time series are saved as bytestring. Thus, compressed they are not human readable anymore. Furthmore, filter functionalities are not working. Therefore, you always need to call the entire time series. You cannot only read some parts of it. Especially, for web applications is usually does not make much sense to compress your data.\n",
    "\n",
    "To call the time series, use following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_api.get_timeseries_from_db(filter_document={'data_type':'p_mw'}, \n",
    "                              collection_name=\"timeseries\", \n",
    "                              global_database=True,\n",
    "                              compressed_ts_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the `filter_document` dict you can pass everything you want. The database matching the filter criteria are extracted accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want, you can also extract the time series metadata. Just set `include_metadata` equal to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_api.get_timeseries_from_db(filter_document={'data_type':'p_mw'}, \n",
    "                              collection_name=\"timeseries\", \n",
    "                              global_database=True,\n",
    "                              compressed_ts_data=False, \n",
    "                              include_metadata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et voil√†, you are now able to save and call time series in pandahub!\n",
    "\n",
    "**multiple time series**\n",
    "\n",
    "In case of calling multiple time series the procedure is slightly different compare to a single time series. At first, we add a second time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_data = pd.Series(np.random.random(35040))\n",
    "ph_api.write_timeseries_to_db(timeseries_data, \n",
    "                              data_type='p_mw', \n",
    "                              collection_name=\"timeseries\", \n",
    "                              global_database=True, \n",
    "                              compress_ts_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to get the time series with the function above leads to following error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_api.get_timeseries_from_db(filter_document={'data_type':'p_mw'}, \n",
    "                              collection_name=\"timeseries\", \n",
    "                              global_database=True,\n",
    "                              compressed_ts_data=False, \n",
    "                              include_metadata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you still want to retrieve both time series, you need to call another function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_api.multi_get_timeseries_from_db(filter_document={'data_type':'p_mw'}, \n",
    "                                    collection_name=\"timeseries\", \n",
    "                                    global_database=True,\n",
    "                                    compressed_ts_data=False, \n",
    "                                    include_metadata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function above, you are now able to get all time series matching the filter criteria above and do your postprocessing apart from the database."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
